# Задание

Необходимо реализовать нейронную сеть вычисляющую результат заданной логической операции. Затем реализовать функции, которые будут симулировать работу построенной модели. Функции должны принимать тензор входных данных и список весов. Должно быть реализовано 2 функции:
+ Функция, в которой все операции реализованы как поэлементные операции над тензорами
+ Функция, в которой все операции реализованы с использованием операций над тензорами из NumPy


Для проверки корректности работы функций необходимо:
+ Инициализировать модель и получить из нее веса
+ Прогнать датасет через не обученную модель и реализованные 2 функции. Сравнить результат.
+ Обучить модель и получить веса после обучения
+ Прогнать датасет через обученную модель и реализованные 2 функции. Сравнить результат.


## Вариант 4
(a **or** b) **and** (b **or** c)

# Реализация функций

Была реализована нейронная сеть для предсказания результата логической операции. Задачу можно рассматривать как задачу бинарной классификации. 
Модель включает в себя слой из 6 нейронов, использующий функцию активации `relu`, и выходной слой из 1 нейрона с функцией активации `sigmoid`. 
Работу модели можно записать в следующем виде:

    output = sigmoid(dot(w2, relu(dot(w1, x) + b1)) + b2)

Здесь `w1`, `b1` – матрица (двумерный тензор) весов и вектор смещения первого слоя, `w2`, `b2` – веса и смещение второго слоя, `x` – тензор исходных данных, функция `relu(x)` эквивалентна операции `max(x, 0)`, функция `sigmoid(x)` имеет вид `1 / (1 + exp(-x))`. 

Для симуляции работы нейронной сети были реализованы две функции, принимающие тензор входных данных и список весов модели. Список весов имеет следущую структуру: 

    [[w1, b1],
     [w2, b2]].
Здесь `wi`, `bi` – двумерный тензор весов и вектор смещения i-го слоя. Так как операции, выполняемые на разных слоях, различаются только функцией активации, проход данных по слоям модели реализован в виде цикла, а функции активации были созданы отдельно и перечислены в списке. 

Функция `naive_simulation` симулирует работу модели, выполняя все операции поэлементно. Для нее были реализованы две вспомогательные функции: функция `naive_matrix_vector_dot`, которая осуществляет умножение вектора входных данных на матрицу весов, и функция `naive_add`, осуществляющая поэлементное сложение двух векторов. Для каждого слоя получаем вектор `dot(w, x) + b`, над каждым элементом которого затем выполняется функция активации текущего слоя. Результат выполнения функции активации является тензором входных данных для следующего слоя. 

Функция `np_simulation` симулирует работу модели при помощи операций над тензорами из модуля NumPy. Функции активации `relu` и `sigmoid` изначально были реализованы с использованием методов NumPy, что позволяет применять их сразу ко всему вектору `dot(w, x) + b`.

# Проверка работы функций

Исходные данные:

    x:  [[0 0 0]
         [0 0 1]
         [0 1 0]
         [0 1 1]
         [1 0 0]
         [1 0 1]
         [1 1 0]
         [1 1 1]]
Сначала прогоним данные через необученную модель, вызвав метод `model.predict(x)`. Затем вызовем реализованные функции. Получим следующие результаты: 

    ПРОГОН ЧЕРЕЗ МОДЕЛЬ
    [[0.5       ]
     [0.45779854]
     [0.45981777]
     [0.4599212 ]
     [0.5265067 ]
     [0.56712896]
     [0.6040355 ]
     [0.5929729 ]]
    ПОЭЛЕМЕНТНЫЕ ОПЕРАЦИИ
    [[0.5       ]
     [0.45779853]
     [0.45981776]
     [0.45992122]
     [0.5265067 ]
     [0.56712898]
     [0.60403554]
     [0.59297288]]
    ОПЕРАЦИИ НАД ТЕНЗОРАМИ
    [[0.5       ]
     [0.45779853]
     [0.45981776]
     [0.45992122]
     [0.52650669]
     [0.56712898]
     [0.60403554]
     [0.59297288]]
Как видно, значения, предсказанные моделью, незначительно отличатся от значений, возвращенных функциями.

Обучим модель в течение 180 эпох. Вектор выходных данных для обучения получен в результате выполнения заданной операции над каждой строкой тензора входных данных: 

    y:  [0 0 1 1 0 1 1 1]
В результате прогона данных через обученную модель и вызова реализованных функций со скорректированными весами получим:

    ПРОГОН ЧЕРЕЗ МОДЕЛЬ
    [[0.49424648]
     [0.47362304]
     [0.6114542 ]
     [0.63008523]
     [0.5294799 ]
     [0.6988415 ]
     [0.7493442 ]
     [0.778777  ]]
    ПОЭЛЕМЕНТНЫЕ ОПЕРАЦИИ
    [[0.49424647]
     [0.47362305]
     [0.61145421]
     [0.63008521]
     [0.52947991]
     [0.69884153]
     [0.74934419]
     [0.77877698]]
    ОПЕРАЦИИ НАД ТЕНЗОРАМИ
    [[0.49424647]
     [0.47362305]
     [0.61145421]
     [0.63008521]
     [0.52947991]
     [0.69884154]
     [0.74934419]
     [0.778777  ]]
Точность предсказания модели довольно низкая, однако значительных различий между результатами, полученными при помощи нейросети, и результатами, полученными при помощи реализованных функций, нет, что свидетельствует о корректности работы функций.